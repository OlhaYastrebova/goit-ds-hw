{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNlwPMveee4eRXDJa9D62mu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OlhaYastrebova/goit-ds-hw/blob/main/Hw_12.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras import layers, models\n",
        "from keras.utils import to_categorical\n",
        "from keras.datasets import fashion_mnist\n",
        "\n",
        "# Завантажуємо дані\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "\n",
        "# Нормалізуємо зображення (перетворимо на плаваючі значення між 0 і 1)\n",
        "train_images = train_images.reshape((60000, 28 * 28)).astype('float32') / 255\n",
        "test_images = test_images.reshape((10000, 28 * 28)).astype('float32') / 255\n",
        "\n",
        "# Кодуємо мітки\n",
        "train_labels = to_categorical(train_labels)\n",
        "test_labels = to_categorical(test_labels)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJ37XzI-k1NW",
        "outputId": "11302d3c-a11b-477b-e2a8-e0ec3678c404"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "\u001b[1m29515/29515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "\u001b[1m26421880/26421880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "\u001b[1m5148/5148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "\u001b[1m4422102/4422102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Будуємо модель\n",
        "model = models.Sequential()\n",
        "\n",
        "# Вхідний шар\n",
        "model.add(layers.Input(shape=(28 * 28,)))\n",
        "\n",
        "# Перший прихований шар\n",
        "model.add(layers.Dense(512, activation='relu'))\n",
        "model.add(layers.Dropout(0.5))  # Dropout для регуляризації\n",
        "\n",
        "# Другий прихований шар\n",
        "model.add(layers.Dense(256, activation='relu'))\n",
        "model.add(layers.Dropout(0.5))\n",
        "\n",
        "# Вихідний шар\n",
        "model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "# Компіляція моделі\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Навчання моделі\n",
        "history = model.fit(train_images, train_labels,\n",
        "                    epochs=20,\n",
        "                    batch_size=64,\n",
        "                    validation_split=0.2)\n",
        "\n",
        "# Оцінка моделі на тестових даних\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print(f'Test accuracy: {test_acc:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_LSUF1aflcmV",
        "outputId": "0faab3cd-3fcb-4c9e-b1f5-beab59411eb1"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.6867 - loss: 0.8726 - val_accuracy: 0.8345 - val_loss: 0.4434\n",
            "Epoch 2/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8152 - loss: 0.5082 - val_accuracy: 0.8487 - val_loss: 0.4198\n",
            "Epoch 3/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8343 - loss: 0.4533 - val_accuracy: 0.8572 - val_loss: 0.3857\n",
            "Epoch 4/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8469 - loss: 0.4200 - val_accuracy: 0.8610 - val_loss: 0.3846\n",
            "Epoch 5/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8468 - loss: 0.4177 - val_accuracy: 0.8712 - val_loss: 0.3551\n",
            "Epoch 6/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8592 - loss: 0.3942 - val_accuracy: 0.8708 - val_loss: 0.3529\n",
            "Epoch 7/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8596 - loss: 0.3836 - val_accuracy: 0.8763 - val_loss: 0.3447\n",
            "Epoch 8/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8609 - loss: 0.3852 - val_accuracy: 0.8770 - val_loss: 0.3406\n",
            "Epoch 9/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8659 - loss: 0.3679 - val_accuracy: 0.8767 - val_loss: 0.3377\n",
            "Epoch 10/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8687 - loss: 0.3542 - val_accuracy: 0.8791 - val_loss: 0.3399\n",
            "Epoch 11/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8659 - loss: 0.3617 - val_accuracy: 0.8811 - val_loss: 0.3206\n",
            "Epoch 12/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8709 - loss: 0.3522 - val_accuracy: 0.8798 - val_loss: 0.3273\n",
            "Epoch 13/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8758 - loss: 0.3346 - val_accuracy: 0.8820 - val_loss: 0.3262\n",
            "Epoch 14/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8708 - loss: 0.3473 - val_accuracy: 0.8840 - val_loss: 0.3235\n",
            "Epoch 15/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8767 - loss: 0.3344 - val_accuracy: 0.8827 - val_loss: 0.3298\n",
            "Epoch 16/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8764 - loss: 0.3354 - val_accuracy: 0.8823 - val_loss: 0.3228\n",
            "Epoch 17/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8810 - loss: 0.3226 - val_accuracy: 0.8780 - val_loss: 0.3366\n",
            "Epoch 18/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8768 - loss: 0.3332 - val_accuracy: 0.8828 - val_loss: 0.3268\n",
            "Epoch 19/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8801 - loss: 0.3227 - val_accuracy: 0.8842 - val_loss: 0.3298\n",
            "Epoch 20/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8827 - loss: 0.3160 - val_accuracy: 0.8868 - val_loss: 0.3253\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8767 - loss: 0.3448\n",
            "Test accuracy: 0.8774\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "\n",
        "# Прогнозування на тестових даних\n",
        "y_pred = model.predict(test_images)\n",
        "\n",
        "# Перетворюємо one-hot encoded мітки на звичайні\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_true_classes = np.argmax(test_labels, axis=1)\n",
        "\n",
        "# Виведення classification_report\n",
        "report = classification_report(y_true_classes, y_pred_classes, target_names=[\n",
        "    'T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "    'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot'])\n",
        "print(report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCkFphxkmn4B",
        "outputId": "87631702-cf22-4859-9263-2a76cc64416b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            " T-shirt/top       0.84      0.81      0.82      1000\n",
            "     Trouser       0.98      0.97      0.98      1000\n",
            "    Pullover       0.74      0.84      0.79      1000\n",
            "       Dress       0.84      0.91      0.87      1000\n",
            "        Coat       0.80      0.78      0.79      1000\n",
            "      Sandal       0.99      0.95      0.97      1000\n",
            "       Shirt       0.72      0.64      0.67      1000\n",
            "     Sneaker       0.92      0.97      0.94      1000\n",
            "         Bag       0.98      0.96      0.97      1000\n",
            "  Ankle boot       0.97      0.95      0.96      1000\n",
            "\n",
            "    accuracy                           0.88     10000\n",
            "   macro avg       0.88      0.88      0.88     10000\n",
            "weighted avg       0.88      0.88      0.88     10000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Будуємо модель\n",
        "model = models.Sequential()\n",
        "\n",
        "# Вхідний шар\n",
        "model.add(layers.Input(shape=(28 * 28,)))\n",
        "\n",
        "# Перший прихований шар\n",
        "model.add(layers.Dense(256, activation='relu'))\n",
        "\n",
        "# Другий прихований шар\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "\n",
        "# Вихідний шар\n",
        "model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "# Компіляція моделі\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Навчання моделі\n",
        "history = model.fit(train_images, train_labels,\n",
        "                    epochs=20,\n",
        "                    batch_size=128,\n",
        "                    validation_split=0.2)\n",
        "\n",
        "# Оцінка моделі на тестових даних\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print(f'Test accuracy: {test_acc:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DNALOcMunc_l",
        "outputId": "7a74ca02-d352-46d9-dd7f-7e3c5adde812"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7479 - loss: 0.7304 - val_accuracy: 0.8431 - val_loss: 0.4325\n",
            "Epoch 2/20\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8573 - loss: 0.4007 - val_accuracy: 0.8639 - val_loss: 0.3773\n",
            "Epoch 3/20\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8750 - loss: 0.3417 - val_accuracy: 0.8711 - val_loss: 0.3472\n",
            "Epoch 4/20\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8885 - loss: 0.3064 - val_accuracy: 0.8718 - val_loss: 0.3526\n",
            "Epoch 5/20\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8912 - loss: 0.2932 - val_accuracy: 0.8871 - val_loss: 0.3228\n",
            "Epoch 6/20\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8979 - loss: 0.2747 - val_accuracy: 0.8831 - val_loss: 0.3254\n",
            "Epoch 7/20\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9074 - loss: 0.2512 - val_accuracy: 0.8874 - val_loss: 0.3110\n",
            "Epoch 8/20\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9109 - loss: 0.2444 - val_accuracy: 0.8809 - val_loss: 0.3299\n",
            "Epoch 9/20\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9095 - loss: 0.2395 - val_accuracy: 0.8844 - val_loss: 0.3281\n",
            "Epoch 10/20\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9160 - loss: 0.2283 - val_accuracy: 0.8852 - val_loss: 0.3286\n",
            "Epoch 11/20\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9203 - loss: 0.2196 - val_accuracy: 0.8834 - val_loss: 0.3410\n",
            "Epoch 12/20\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9211 - loss: 0.2115 - val_accuracy: 0.8888 - val_loss: 0.3177\n",
            "Epoch 13/20\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9236 - loss: 0.1991 - val_accuracy: 0.8840 - val_loss: 0.3414\n",
            "Epoch 14/20\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9260 - loss: 0.1943 - val_accuracy: 0.8931 - val_loss: 0.3116\n",
            "Epoch 15/20\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9312 - loss: 0.1790 - val_accuracy: 0.8904 - val_loss: 0.3157\n",
            "Epoch 16/20\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9320 - loss: 0.1838 - val_accuracy: 0.8965 - val_loss: 0.3061\n",
            "Epoch 17/20\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9349 - loss: 0.1719 - val_accuracy: 0.8972 - val_loss: 0.3169\n",
            "Epoch 18/20\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9391 - loss: 0.1666 - val_accuracy: 0.8972 - val_loss: 0.3253\n",
            "Epoch 19/20\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9396 - loss: 0.1605 - val_accuracy: 0.8892 - val_loss: 0.3492\n",
            "Epoch 20/20\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9430 - loss: 0.1517 - val_accuracy: 0.8928 - val_loss: 0.3401\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8837 - loss: 0.3773\n",
            "Test accuracy: 0.8827\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Прогнозування на тестових даних\n",
        "y_pred = model.predict(test_images)\n",
        "\n",
        "# Перетворюємо one-hot encoded мітки на звичайні\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_true_classes = np.argmax(test_labels, axis=1)\n",
        "\n",
        "# Виведення classification_report\n",
        "report = classification_report(y_true_classes, y_pred_classes, target_names=[\n",
        "    'T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "    'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot'])\n",
        "print(report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mlJBxe63oAMZ",
        "outputId": "e9b17d3c-940f-498a-acfc-693fe5fabef5"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            " T-shirt/top       0.80      0.87      0.84      1000\n",
            "     Trouser       0.99      0.97      0.98      1000\n",
            "    Pullover       0.79      0.79      0.79      1000\n",
            "       Dress       0.93      0.83      0.88      1000\n",
            "        Coat       0.71      0.90      0.80      1000\n",
            "      Sandal       0.98      0.96      0.97      1000\n",
            "       Shirt       0.79      0.61      0.69      1000\n",
            "     Sneaker       0.93      0.97      0.95      1000\n",
            "         Bag       0.98      0.98      0.98      1000\n",
            "  Ankle boot       0.97      0.95      0.96      1000\n",
            "\n",
            "    accuracy                           0.88     10000\n",
            "   macro avg       0.89      0.88      0.88     10000\n",
            "weighted avg       0.89      0.88      0.88     10000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Будуємо модель\n",
        "model = models.Sequential()\n",
        "\n",
        "# Вхідний шар\n",
        "model.add(layers.Input(shape=(28 * 28,)))\n",
        "\n",
        "# Перший прихований шар\n",
        "model.add(layers.Dense(512, activation='relu'))\n",
        "\n",
        "# Другий прихований шар\n",
        "model.add(layers.Dense(256, activation='relu'))\n",
        "\n",
        "\n",
        "# Вихідний шар\n",
        "model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "# Компіляція моделі\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Навчання моделі\n",
        "history = model.fit(train_images, train_labels,\n",
        "                    epochs=30,\n",
        "                    batch_size=128,\n",
        "                    validation_split=0.2)\n",
        "\n",
        "# Оцінка моделі на тестових даних\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print(f'Test accuracy: {test_acc:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k5FhJrOun5Pz",
        "outputId": "e16b1a6b-e033-4c50-e79f-09b367a16792"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.7647 - loss: 0.6718 - val_accuracy: 0.8500 - val_loss: 0.4152\n",
            "Epoch 2/30\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8618 - loss: 0.3760 - val_accuracy: 0.8713 - val_loss: 0.3591\n",
            "Epoch 3/30\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8776 - loss: 0.3281 - val_accuracy: 0.8529 - val_loss: 0.4107\n",
            "Epoch 4/30\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8846 - loss: 0.3047 - val_accuracy: 0.8819 - val_loss: 0.3237\n",
            "Epoch 5/30\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8982 - loss: 0.2749 - val_accuracy: 0.8797 - val_loss: 0.3378\n",
            "Epoch 6/30\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9024 - loss: 0.2637 - val_accuracy: 0.8835 - val_loss: 0.3267\n",
            "Epoch 7/30\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9056 - loss: 0.2477 - val_accuracy: 0.8752 - val_loss: 0.3404\n",
            "Epoch 8/30\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9071 - loss: 0.2446 - val_accuracy: 0.8899 - val_loss: 0.3148\n",
            "Epoch 9/30\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9165 - loss: 0.2266 - val_accuracy: 0.8898 - val_loss: 0.3112\n",
            "Epoch 10/30\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9182 - loss: 0.2140 - val_accuracy: 0.8893 - val_loss: 0.3056\n",
            "Epoch 11/30\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9221 - loss: 0.2074 - val_accuracy: 0.8891 - val_loss: 0.3195\n",
            "Epoch 12/30\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9230 - loss: 0.1987 - val_accuracy: 0.8951 - val_loss: 0.3100\n",
            "Epoch 13/30\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9290 - loss: 0.1877 - val_accuracy: 0.8943 - val_loss: 0.3149\n",
            "Epoch 14/30\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9312 - loss: 0.1827 - val_accuracy: 0.8950 - val_loss: 0.3117\n",
            "Epoch 15/30\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9347 - loss: 0.1726 - val_accuracy: 0.8836 - val_loss: 0.3603\n",
            "Epoch 16/30\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9392 - loss: 0.1660 - val_accuracy: 0.8940 - val_loss: 0.3231\n",
            "Epoch 17/30\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9392 - loss: 0.1596 - val_accuracy: 0.8966 - val_loss: 0.3230\n",
            "Epoch 18/30\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9443 - loss: 0.1487 - val_accuracy: 0.8935 - val_loss: 0.3405\n",
            "Epoch 19/30\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9435 - loss: 0.1499 - val_accuracy: 0.8928 - val_loss: 0.3686\n",
            "Epoch 20/30\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9468 - loss: 0.1411 - val_accuracy: 0.8967 - val_loss: 0.3314\n",
            "Epoch 21/30\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9485 - loss: 0.1381 - val_accuracy: 0.8958 - val_loss: 0.3574\n",
            "Epoch 22/30\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9488 - loss: 0.1331 - val_accuracy: 0.8958 - val_loss: 0.3488\n",
            "Epoch 23/30\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9532 - loss: 0.1265 - val_accuracy: 0.8940 - val_loss: 0.3630\n",
            "Epoch 24/30\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9517 - loss: 0.1260 - val_accuracy: 0.8936 - val_loss: 0.3774\n",
            "Epoch 25/30\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9550 - loss: 0.1161 - val_accuracy: 0.8928 - val_loss: 0.3946\n",
            "Epoch 26/30\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9571 - loss: 0.1125 - val_accuracy: 0.8954 - val_loss: 0.3754\n",
            "Epoch 27/30\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9571 - loss: 0.1125 - val_accuracy: 0.8981 - val_loss: 0.3917\n",
            "Epoch 28/30\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9607 - loss: 0.1062 - val_accuracy: 0.8959 - val_loss: 0.4138\n",
            "Epoch 29/30\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9607 - loss: 0.1034 - val_accuracy: 0.8975 - val_loss: 0.4053\n",
            "Epoch 30/30\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9618 - loss: 0.1002 - val_accuracy: 0.8923 - val_loss: 0.3978\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8874 - loss: 0.4239\n",
            "Test accuracy: 0.8874\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Прогнозування на тестових даних\n",
        "y_pred = model.predict(test_images)\n",
        "\n",
        "# Перетворюємо one-hot encoded мітки на звичайні\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_true_classes = np.argmax(test_labels, axis=1)\n",
        "\n",
        "# Виведення classification_report\n",
        "report = classification_report(y_true_classes, y_pred_classes, target_names=[\n",
        "    'T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "    'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot'])\n",
        "print(report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mgm5XfnUohja",
        "outputId": "ea316340-e6e1-44e2-cdda-dc36cb86dfb4"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            " T-shirt/top       0.85      0.81      0.83      1000\n",
            "     Trouser       0.98      0.99      0.98      1000\n",
            "    Pullover       0.83      0.76      0.79      1000\n",
            "       Dress       0.91      0.89      0.90      1000\n",
            "        Coat       0.79      0.85      0.82      1000\n",
            "      Sandal       0.99      0.95      0.97      1000\n",
            "       Shirt       0.68      0.73      0.71      1000\n",
            "     Sneaker       0.94      0.97      0.95      1000\n",
            "         Bag       0.97      0.97      0.97      1000\n",
            "  Ankle boot       0.95      0.96      0.96      1000\n",
            "\n",
            "    accuracy                           0.89     10000\n",
            "   macro avg       0.89      0.89      0.89     10000\n",
            "weighted avg       0.89      0.89      0.89     10000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import layers, models, regularizers\n",
        "\n",
        "# Будуємо модель\n",
        "model = models.Sequential()\n",
        "\n",
        "# Вхідний шар\n",
        "model.add(layers.Input(shape=(28 * 28,)))\n",
        "\n",
        "# Приховані шари\n",
        "model.add(layers.Dense(1024, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(512, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(256, activation='relu'))\n",
        "\n",
        "# Вихідний шар\n",
        "model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "# Компіляція моделі\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Навчання моделі\n",
        "model.fit(train_images, train_labels,\n",
        "          epochs=30,\n",
        "          batch_size=128,\n",
        "          validation_split=0.2)\n",
        "\n",
        "# Оцінка моделі на тестових даних\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print(f'Test accuracy: {test_acc:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rDBeYYTzpDXA",
        "outputId": "ef165c53-190e-4492-ceda-e2287a3fa575"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.6870 - loss: 1.8659 - val_accuracy: 0.8348 - val_loss: 0.8738\n",
            "Epoch 2/30\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8199 - loss: 0.8610 - val_accuracy: 0.8446 - val_loss: 0.6599\n",
            "Epoch 3/30\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8249 - loss: 0.7048 - val_accuracy: 0.8419 - val_loss: 0.6114\n",
            "Epoch 4/30\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8254 - loss: 0.6540 - val_accuracy: 0.8444 - val_loss: 0.5747\n",
            "Epoch 5/30\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8310 - loss: 0.6225 - val_accuracy: 0.8573 - val_loss: 0.5502\n",
            "Epoch 6/30\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8287 - loss: 0.6076 - val_accuracy: 0.8597 - val_loss: 0.5277\n",
            "Epoch 7/30\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8294 - loss: 0.6000 - val_accuracy: 0.8606 - val_loss: 0.5208\n",
            "Epoch 8/30\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8332 - loss: 0.5858 - val_accuracy: 0.8605 - val_loss: 0.5170\n",
            "Epoch 9/30\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8321 - loss: 0.5887 - val_accuracy: 0.8538 - val_loss: 0.5146\n",
            "Epoch 10/30\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8330 - loss: 0.5818 - val_accuracy: 0.8555 - val_loss: 0.5157\n",
            "Epoch 11/30\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8352 - loss: 0.5842 - val_accuracy: 0.8602 - val_loss: 0.5045\n",
            "Epoch 12/30\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8327 - loss: 0.5772 - val_accuracy: 0.8630 - val_loss: 0.5009\n",
            "Epoch 13/30\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8344 - loss: 0.5809 - val_accuracy: 0.8503 - val_loss: 0.5189\n",
            "Epoch 14/30\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8340 - loss: 0.5735 - val_accuracy: 0.8646 - val_loss: 0.4957\n",
            "Epoch 15/30\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8359 - loss: 0.5685 - val_accuracy: 0.8648 - val_loss: 0.4912\n",
            "Epoch 16/30\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8347 - loss: 0.5674 - val_accuracy: 0.8646 - val_loss: 0.5018\n",
            "Epoch 17/30\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8355 - loss: 0.5739 - val_accuracy: 0.8612 - val_loss: 0.4945\n",
            "Epoch 18/30\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8406 - loss: 0.5583 - val_accuracy: 0.8574 - val_loss: 0.4942\n",
            "Epoch 19/30\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8400 - loss: 0.5543 - val_accuracy: 0.8661 - val_loss: 0.4898\n",
            "Epoch 20/30\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8400 - loss: 0.5511 - val_accuracy: 0.8589 - val_loss: 0.4940\n",
            "Epoch 21/30\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8371 - loss: 0.5608 - val_accuracy: 0.8645 - val_loss: 0.4919\n",
            "Epoch 22/30\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8358 - loss: 0.5618 - val_accuracy: 0.8610 - val_loss: 0.4856\n",
            "Epoch 23/30\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8348 - loss: 0.5633 - val_accuracy: 0.8585 - val_loss: 0.4941\n",
            "Epoch 24/30\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8397 - loss: 0.5596 - val_accuracy: 0.8619 - val_loss: 0.4917\n",
            "Epoch 25/30\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8354 - loss: 0.5640 - val_accuracy: 0.8639 - val_loss: 0.4812\n",
            "Epoch 26/30\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8412 - loss: 0.5441 - val_accuracy: 0.8584 - val_loss: 0.4878\n",
            "Epoch 27/30\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8380 - loss: 0.5570 - val_accuracy: 0.8558 - val_loss: 0.4992\n",
            "Epoch 28/30\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8396 - loss: 0.5474 - val_accuracy: 0.8621 - val_loss: 0.4908\n",
            "Epoch 29/30\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8361 - loss: 0.5548 - val_accuracy: 0.8631 - val_loss: 0.4891\n",
            "Epoch 30/30\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8361 - loss: 0.5562 - val_accuracy: 0.8633 - val_loss: 0.4843\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8562 - loss: 0.4988\n",
            "Test accuracy: 0.8533\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Прогнозування на тестових даних\n",
        "y_pred = model.predict(test_images)\n",
        "\n",
        "# Перетворюємо one-hot encoded мітки на звичайні\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_true_classes = np.argmax(test_labels, axis=1)\n",
        "\n",
        "# Виведення classification_report\n",
        "report = classification_report(y_true_classes, y_pred_classes, target_names=[\n",
        "    'T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "    'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot'])\n",
        "print(report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RXQ8oBfAql8M",
        "outputId": "edecc5ef-437c-4ac5-eb3a-510f4ea8fbf0"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            " T-shirt/top       0.76      0.85      0.80      1000\n",
            "     Trouser       0.98      0.96      0.97      1000\n",
            "    Pullover       0.77      0.73      0.75      1000\n",
            "       Dress       0.83      0.90      0.86      1000\n",
            "        Coat       0.75      0.79      0.77      1000\n",
            "      Sandal       0.97      0.92      0.94      1000\n",
            "       Shirt       0.69      0.51      0.59      1000\n",
            "     Sneaker       0.90      0.95      0.93      1000\n",
            "         Bag       0.93      0.97      0.95      1000\n",
            "  Ankle boot       0.94      0.94      0.94      1000\n",
            "\n",
            "    accuracy                           0.85     10000\n",
            "   macro avg       0.85      0.85      0.85     10000\n",
            "weighted avg       0.85      0.85      0.85     10000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import layers, models, regularizers\n",
        "\n",
        "# Будуємо модель\n",
        "model = models.Sequential()\n",
        "\n",
        "# Вхідний шар\n",
        "model.add(layers.Input(shape=(28 * 28,)))\n",
        "\n",
        "# Приховані шари\n",
        "model.add(layers.Dense(1024, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
        "\n",
        "model.add(layers.Dense(512, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
        "\n",
        "model.add(layers.Dense(256, activation='relu'))\n",
        "\n",
        "# Вихідний шар\n",
        "model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "# Компіляція моделі\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Навчання моделі\n",
        "model.fit(train_images, train_labels,\n",
        "          epochs=50,\n",
        "          batch_size=128,\n",
        "          validation_split=0.2)\n",
        "\n",
        "# Оцінка моделі на тестових даних\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print(f'Test accuracy: {test_acc:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_s4Kr_qwuS52",
        "outputId": "257ad153-7c66-4e0a-f2f4-f0ed5b74f780"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.7581 - loss: 1.5778 - val_accuracy: 0.8270 - val_loss: 0.7949\n",
            "Epoch 2/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8482 - loss: 0.6714 - val_accuracy: 0.8442 - val_loss: 0.5886\n",
            "Epoch 3/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8566 - loss: 0.5388 - val_accuracy: 0.8641 - val_loss: 0.4947\n",
            "Epoch 4/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8685 - loss: 0.4748 - val_accuracy: 0.8588 - val_loss: 0.4834\n",
            "Epoch 5/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8739 - loss: 0.4379 - val_accuracy: 0.8652 - val_loss: 0.4508\n",
            "Epoch 6/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8759 - loss: 0.4237 - val_accuracy: 0.8727 - val_loss: 0.4345\n",
            "Epoch 7/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8815 - loss: 0.4032 - val_accuracy: 0.8769 - val_loss: 0.4220\n",
            "Epoch 8/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8842 - loss: 0.3879 - val_accuracy: 0.8732 - val_loss: 0.4264\n",
            "Epoch 9/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8862 - loss: 0.3780 - val_accuracy: 0.8768 - val_loss: 0.4110\n",
            "Epoch 10/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8893 - loss: 0.3713 - val_accuracy: 0.8767 - val_loss: 0.4134\n",
            "Epoch 11/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8923 - loss: 0.3630 - val_accuracy: 0.8783 - val_loss: 0.4194\n",
            "Epoch 12/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8936 - loss: 0.3590 - val_accuracy: 0.8831 - val_loss: 0.3951\n",
            "Epoch 13/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8929 - loss: 0.3560 - val_accuracy: 0.8797 - val_loss: 0.4078\n",
            "Epoch 14/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8969 - loss: 0.3496 - val_accuracy: 0.8829 - val_loss: 0.3968\n",
            "Epoch 15/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8995 - loss: 0.3413 - val_accuracy: 0.8752 - val_loss: 0.4098\n",
            "Epoch 16/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9011 - loss: 0.3342 - val_accuracy: 0.8814 - val_loss: 0.3896\n",
            "Epoch 17/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9051 - loss: 0.3250 - val_accuracy: 0.8755 - val_loss: 0.4041\n",
            "Epoch 18/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9039 - loss: 0.3288 - val_accuracy: 0.8822 - val_loss: 0.3941\n",
            "Epoch 19/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9058 - loss: 0.3218 - val_accuracy: 0.8799 - val_loss: 0.3918\n",
            "Epoch 20/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9050 - loss: 0.3231 - val_accuracy: 0.8791 - val_loss: 0.3983\n",
            "Epoch 21/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9046 - loss: 0.3219 - val_accuracy: 0.8723 - val_loss: 0.4143\n",
            "Epoch 22/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9053 - loss: 0.3189 - val_accuracy: 0.8832 - val_loss: 0.3809\n",
            "Epoch 23/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9067 - loss: 0.3148 - val_accuracy: 0.8783 - val_loss: 0.4096\n",
            "Epoch 24/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9051 - loss: 0.3117 - val_accuracy: 0.8772 - val_loss: 0.3961\n",
            "Epoch 25/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9056 - loss: 0.3116 - val_accuracy: 0.8870 - val_loss: 0.3892\n",
            "Epoch 26/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9095 - loss: 0.3097 - val_accuracy: 0.8877 - val_loss: 0.3852\n",
            "Epoch 27/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9120 - loss: 0.2995 - val_accuracy: 0.8837 - val_loss: 0.3874\n",
            "Epoch 28/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9130 - loss: 0.2978 - val_accuracy: 0.8855 - val_loss: 0.3834\n",
            "Epoch 29/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9107 - loss: 0.3020 - val_accuracy: 0.8806 - val_loss: 0.3931\n",
            "Epoch 30/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9109 - loss: 0.3008 - val_accuracy: 0.8858 - val_loss: 0.3937\n",
            "Epoch 31/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9104 - loss: 0.3031 - val_accuracy: 0.8800 - val_loss: 0.4027\n",
            "Epoch 32/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9128 - loss: 0.2935 - val_accuracy: 0.8781 - val_loss: 0.4032\n",
            "Epoch 33/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9132 - loss: 0.2962 - val_accuracy: 0.8770 - val_loss: 0.4035\n",
            "Epoch 34/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9167 - loss: 0.2833 - val_accuracy: 0.8817 - val_loss: 0.4062\n",
            "Epoch 35/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9124 - loss: 0.2962 - val_accuracy: 0.8792 - val_loss: 0.3936\n",
            "Epoch 36/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9167 - loss: 0.2870 - val_accuracy: 0.8848 - val_loss: 0.4057\n",
            "Epoch 37/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9158 - loss: 0.2891 - val_accuracy: 0.8759 - val_loss: 0.4104\n",
            "Epoch 38/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9152 - loss: 0.2879 - val_accuracy: 0.8860 - val_loss: 0.3889\n",
            "Epoch 39/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9152 - loss: 0.2862 - val_accuracy: 0.8819 - val_loss: 0.4034\n",
            "Epoch 40/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9128 - loss: 0.2940 - val_accuracy: 0.8826 - val_loss: 0.4132\n",
            "Epoch 41/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9185 - loss: 0.2825 - val_accuracy: 0.8682 - val_loss: 0.4305\n",
            "Epoch 42/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9178 - loss: 0.2836 - val_accuracy: 0.8800 - val_loss: 0.4030\n",
            "Epoch 43/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9171 - loss: 0.2818 - val_accuracy: 0.8902 - val_loss: 0.3801\n",
            "Epoch 44/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9199 - loss: 0.2740 - val_accuracy: 0.8776 - val_loss: 0.4019\n",
            "Epoch 45/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9195 - loss: 0.2823 - val_accuracy: 0.8839 - val_loss: 0.3985\n",
            "Epoch 46/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9159 - loss: 0.2840 - val_accuracy: 0.8883 - val_loss: 0.4092\n",
            "Epoch 47/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9201 - loss: 0.2752 - val_accuracy: 0.8814 - val_loss: 0.4096\n",
            "Epoch 48/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9197 - loss: 0.2742 - val_accuracy: 0.8896 - val_loss: 0.3940\n",
            "Epoch 49/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9193 - loss: 0.2746 - val_accuracy: 0.8899 - val_loss: 0.4023\n",
            "Epoch 50/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9232 - loss: 0.2738 - val_accuracy: 0.8849 - val_loss: 0.4037\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8832 - loss: 0.4237\n",
            "Test accuracy: 0.8811\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import optimizers, callbacks\n",
        "\n",
        "# Завантажуємо дані\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "\n",
        "# Нормалізуємо зображення\n",
        "train_images = train_images.reshape((60000, 28 * 28)).astype('float32') / 255\n",
        "test_images = test_images.reshape((10000, 28 * 28)).astype('float32') / 255\n",
        "\n",
        "# Кодуємо мітки\n",
        "train_labels_categorical = to_categorical(train_labels)\n",
        "test_labels_categorical = to_categorical(test_labels)\n",
        "\n",
        "# Будуємо модель\n",
        "model = models.Sequential()\n",
        "\n",
        "# Вхідний шар\n",
        "model.add(layers.Input(shape=(28 * 28,)))\n",
        "\n",
        "# Приховані шари\n",
        "model.add(layers.Dense(1024, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(512, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(256, activation='relu'))\n",
        "\n",
        "# Вихідний шар\n",
        "model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "# Компіляція моделі з RMSprop оптимізатором\n",
        "optimizer = optimizers.RMSprop(learning_rate=0.001)\n",
        "model.compile(optimizer=optimizer,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Callbacks: EarlyStopping та ReduceLROnPlateau\n",
        "early_stopping = callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "reduce_lr = callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=0.00001)\n",
        "\n",
        "# Навчання моделі\n",
        "model.fit(train_images, train_labels_categorical,\n",
        "          epochs=50,\n",
        "          batch_size=128,\n",
        "          validation_split=0.2,\n",
        "          callbacks=[early_stopping, reduce_lr])\n",
        "\n",
        "# Оцінка моделі на тестових даних\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels_categorical)\n",
        "print(f'Test accuracy: {test_acc:.4f}')\n",
        "\n",
        "# Прогнозуємо на тестових даних\n",
        "y_pred = model.predict(test_images)\n",
        "\n",
        "# Перетворимо ймовірності на класи\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_true = test_labels\n",
        "\n",
        "# Виведемо звіт про класифікацію\n",
        "print(classification_report(y_true, y_pred_classes))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-hScP4_BraHI",
        "outputId": "f7921420-589b-405c-a877-ac3ac9ef57e2"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.6509 - loss: 1.9818 - val_accuracy: 0.8053 - val_loss: 0.8206 - learning_rate: 0.0010\n",
            "Epoch 2/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8047 - loss: 0.7931 - val_accuracy: 0.8429 - val_loss: 0.6018 - learning_rate: 0.0010\n",
            "Epoch 3/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8127 - loss: 0.6769 - val_accuracy: 0.8258 - val_loss: 0.5995 - learning_rate: 0.0010\n",
            "Epoch 4/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8234 - loss: 0.6235 - val_accuracy: 0.8322 - val_loss: 0.5823 - learning_rate: 0.0010\n",
            "Epoch 5/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8252 - loss: 0.6065 - val_accuracy: 0.8274 - val_loss: 0.5776 - learning_rate: 0.0010\n",
            "Epoch 6/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8283 - loss: 0.5937 - val_accuracy: 0.8506 - val_loss: 0.5188 - learning_rate: 0.0010\n",
            "Epoch 7/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8285 - loss: 0.5853 - val_accuracy: 0.8148 - val_loss: 0.6452 - learning_rate: 0.0010\n",
            "Epoch 8/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8338 - loss: 0.5686 - val_accuracy: 0.8526 - val_loss: 0.5025 - learning_rate: 0.0010\n",
            "Epoch 9/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8351 - loss: 0.5672 - val_accuracy: 0.8528 - val_loss: 0.5215 - learning_rate: 0.0010\n",
            "Epoch 10/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8359 - loss: 0.5609 - val_accuracy: 0.8586 - val_loss: 0.5061 - learning_rate: 0.0010\n",
            "Epoch 11/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8394 - loss: 0.5578 - val_accuracy: 0.8434 - val_loss: 0.5210 - learning_rate: 0.0010\n",
            "Epoch 12/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8553 - loss: 0.4995 - val_accuracy: 0.8688 - val_loss: 0.4510 - learning_rate: 5.0000e-04\n",
            "Epoch 13/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8560 - loss: 0.4862 - val_accuracy: 0.8694 - val_loss: 0.4394 - learning_rate: 5.0000e-04\n",
            "Epoch 14/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8604 - loss: 0.4708 - val_accuracy: 0.8673 - val_loss: 0.4430 - learning_rate: 5.0000e-04\n",
            "Epoch 15/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8613 - loss: 0.4608 - val_accuracy: 0.8707 - val_loss: 0.4343 - learning_rate: 5.0000e-04\n",
            "Epoch 16/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8646 - loss: 0.4571 - val_accuracy: 0.8683 - val_loss: 0.4385 - learning_rate: 5.0000e-04\n",
            "Epoch 17/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8604 - loss: 0.4655 - val_accuracy: 0.8669 - val_loss: 0.4445 - learning_rate: 5.0000e-04\n",
            "Epoch 18/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8608 - loss: 0.4590 - val_accuracy: 0.8752 - val_loss: 0.4273 - learning_rate: 5.0000e-04\n",
            "Epoch 19/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8600 - loss: 0.4553 - val_accuracy: 0.8734 - val_loss: 0.4288 - learning_rate: 5.0000e-04\n",
            "Epoch 20/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8627 - loss: 0.4485 - val_accuracy: 0.8609 - val_loss: 0.4626 - learning_rate: 5.0000e-04\n",
            "Epoch 21/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8633 - loss: 0.4548 - val_accuracy: 0.8782 - val_loss: 0.4183 - learning_rate: 5.0000e-04\n",
            "Epoch 22/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8658 - loss: 0.4534 - val_accuracy: 0.8702 - val_loss: 0.4317 - learning_rate: 5.0000e-04\n",
            "Epoch 23/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8646 - loss: 0.4501 - val_accuracy: 0.8674 - val_loss: 0.4479 - learning_rate: 5.0000e-04\n",
            "Epoch 24/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8652 - loss: 0.4513 - val_accuracy: 0.8702 - val_loss: 0.4284 - learning_rate: 5.0000e-04\n",
            "Epoch 25/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8731 - loss: 0.4206 - val_accuracy: 0.8759 - val_loss: 0.4169 - learning_rate: 2.5000e-04\n",
            "Epoch 26/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8797 - loss: 0.3995 - val_accuracy: 0.8808 - val_loss: 0.3920 - learning_rate: 2.5000e-04\n",
            "Epoch 27/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8770 - loss: 0.3996 - val_accuracy: 0.8807 - val_loss: 0.4007 - learning_rate: 2.5000e-04\n",
            "Epoch 28/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8810 - loss: 0.3940 - val_accuracy: 0.8830 - val_loss: 0.3885 - learning_rate: 2.5000e-04\n",
            "Epoch 29/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8827 - loss: 0.3891 - val_accuracy: 0.8830 - val_loss: 0.3831 - learning_rate: 2.5000e-04\n",
            "Epoch 30/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8820 - loss: 0.3858 - val_accuracy: 0.8832 - val_loss: 0.3830 - learning_rate: 2.5000e-04\n",
            "Epoch 31/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8802 - loss: 0.3906 - val_accuracy: 0.8860 - val_loss: 0.3803 - learning_rate: 2.5000e-04\n",
            "Epoch 32/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8842 - loss: 0.3810 - val_accuracy: 0.8862 - val_loss: 0.3830 - learning_rate: 2.5000e-04\n",
            "Epoch 33/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8828 - loss: 0.3902 - val_accuracy: 0.8864 - val_loss: 0.3762 - learning_rate: 2.5000e-04\n",
            "Epoch 34/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8811 - loss: 0.3882 - val_accuracy: 0.8876 - val_loss: 0.3744 - learning_rate: 2.5000e-04\n",
            "Epoch 35/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8807 - loss: 0.3891 - val_accuracy: 0.8853 - val_loss: 0.3812 - learning_rate: 2.5000e-04\n",
            "Epoch 36/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8846 - loss: 0.3829 - val_accuracy: 0.8829 - val_loss: 0.3891 - learning_rate: 2.5000e-04\n",
            "Epoch 37/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8839 - loss: 0.3812 - val_accuracy: 0.8838 - val_loss: 0.3884 - learning_rate: 2.5000e-04\n",
            "Epoch 38/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8908 - loss: 0.3630 - val_accuracy: 0.8869 - val_loss: 0.3734 - learning_rate: 1.2500e-04\n",
            "Epoch 39/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8951 - loss: 0.3472 - val_accuracy: 0.8872 - val_loss: 0.3654 - learning_rate: 1.2500e-04\n",
            "Epoch 40/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8960 - loss: 0.3490 - val_accuracy: 0.8866 - val_loss: 0.3689 - learning_rate: 1.2500e-04\n",
            "Epoch 41/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8967 - loss: 0.3442 - val_accuracy: 0.8900 - val_loss: 0.3687 - learning_rate: 1.2500e-04\n",
            "Epoch 42/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8972 - loss: 0.3445 - val_accuracy: 0.8813 - val_loss: 0.3798 - learning_rate: 1.2500e-04\n",
            "Epoch 43/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9019 - loss: 0.3287 - val_accuracy: 0.8941 - val_loss: 0.3584 - learning_rate: 6.2500e-05\n",
            "Epoch 44/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9012 - loss: 0.3263 - val_accuracy: 0.8936 - val_loss: 0.3553 - learning_rate: 6.2500e-05\n",
            "Epoch 45/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9051 - loss: 0.3246 - val_accuracy: 0.8916 - val_loss: 0.3583 - learning_rate: 6.2500e-05\n",
            "Epoch 46/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9017 - loss: 0.3281 - val_accuracy: 0.8942 - val_loss: 0.3528 - learning_rate: 6.2500e-05\n",
            "Epoch 47/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9056 - loss: 0.3145 - val_accuracy: 0.8913 - val_loss: 0.3534 - learning_rate: 6.2500e-05\n",
            "Epoch 48/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9024 - loss: 0.3252 - val_accuracy: 0.8926 - val_loss: 0.3559 - learning_rate: 6.2500e-05\n",
            "Epoch 49/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9048 - loss: 0.3135 - val_accuracy: 0.8923 - val_loss: 0.3553 - learning_rate: 6.2500e-05\n",
            "Epoch 50/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9059 - loss: 0.3145 - val_accuracy: 0.8941 - val_loss: 0.3471 - learning_rate: 3.1250e-05\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8875 - loss: 0.3722\n",
            "Test accuracy: 0.8874\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.84      0.84      1000\n",
            "           1       0.98      0.97      0.98      1000\n",
            "           2       0.81      0.80      0.81      1000\n",
            "           3       0.89      0.89      0.89      1000\n",
            "           4       0.79      0.84      0.81      1000\n",
            "           5       0.97      0.96      0.96      1000\n",
            "           6       0.72      0.70      0.71      1000\n",
            "           7       0.94      0.95      0.94      1000\n",
            "           8       0.97      0.97      0.97      1000\n",
            "           9       0.96      0.96      0.96      1000\n",
            "\n",
            "    accuracy                           0.89     10000\n",
            "   macro avg       0.89      0.89      0.89     10000\n",
            "weighted avg       0.89      0.89      0.89     10000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Будуємо модель\n",
        "model = models.Sequential()\n",
        "\n",
        "# Вхідний шар\n",
        "model.add(layers.Input(shape=(28 * 28,)))\n",
        "\n",
        "# Приховані шари\n",
        "model.add(layers.Dense(1024, activation='relu'))\n",
        "\n",
        "model.add(layers.Dense(512, activation='relu'))\n",
        "\n",
        "model.add(layers.Dense(256, activation='relu'))\n",
        "\n",
        "# Вихідний шар\n",
        "model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "# Компіляція моделі з RMSprop оптимізатором\n",
        "optimizer = optimizers.RMSprop(learning_rate=0.001)\n",
        "model.compile(optimizer=optimizer,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Навчання моделі\n",
        "model.fit(train_images, train_labels_categorical,\n",
        "          epochs=50,\n",
        "          batch_size=128,\n",
        "          validation_split=0.2)\n",
        "\n",
        "# Оцінка моделі на тестових даних\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels_categorical)\n",
        "print(f'Test accuracy: {test_acc:.4f}')\n",
        "\n",
        "# Прогнозуємо на тестових даних\n",
        "y_pred = model.predict(test_images)\n",
        "\n",
        "# Перетворимо ймовірності на класи\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_true = test_labels\n",
        "\n",
        "# Виведемо звіт про класифікацію\n",
        "print(classification_report(y_true, y_pred_classes))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3c1t9STTwIKD",
        "outputId": "d0523c5d-e231-4ba4-c6e4-857eb7b60fe5"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6951 - loss: 0.8438 - val_accuracy: 0.8432 - val_loss: 0.4196\n",
            "Epoch 2/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8448 - loss: 0.4150 - val_accuracy: 0.8663 - val_loss: 0.3625\n",
            "Epoch 3/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8683 - loss: 0.3610 - val_accuracy: 0.8685 - val_loss: 0.3637\n",
            "Epoch 4/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8778 - loss: 0.3265 - val_accuracy: 0.8752 - val_loss: 0.3555\n",
            "Epoch 5/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8862 - loss: 0.3015 - val_accuracy: 0.8773 - val_loss: 0.3347\n",
            "Epoch 6/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8949 - loss: 0.2798 - val_accuracy: 0.8757 - val_loss: 0.3612\n",
            "Epoch 7/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8982 - loss: 0.2696 - val_accuracy: 0.8845 - val_loss: 0.3429\n",
            "Epoch 8/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9014 - loss: 0.2616 - val_accuracy: 0.8642 - val_loss: 0.3743\n",
            "Epoch 9/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9071 - loss: 0.2418 - val_accuracy: 0.8802 - val_loss: 0.3432\n",
            "Epoch 10/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9101 - loss: 0.2336 - val_accuracy: 0.8928 - val_loss: 0.3109\n",
            "Epoch 11/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9148 - loss: 0.2259 - val_accuracy: 0.8923 - val_loss: 0.3290\n",
            "Epoch 12/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9191 - loss: 0.2161 - val_accuracy: 0.8844 - val_loss: 0.3510\n",
            "Epoch 13/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9167 - loss: 0.2152 - val_accuracy: 0.8818 - val_loss: 0.4122\n",
            "Epoch 14/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9213 - loss: 0.2066 - val_accuracy: 0.8964 - val_loss: 0.3534\n",
            "Epoch 15/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9233 - loss: 0.2028 - val_accuracy: 0.8836 - val_loss: 0.3921\n",
            "Epoch 16/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9218 - loss: 0.2033 - val_accuracy: 0.8733 - val_loss: 0.5057\n",
            "Epoch 17/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9273 - loss: 0.1963 - val_accuracy: 0.8896 - val_loss: 0.3955\n",
            "Epoch 18/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9261 - loss: 0.1991 - val_accuracy: 0.8953 - val_loss: 0.4169\n",
            "Epoch 19/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9276 - loss: 0.1934 - val_accuracy: 0.8882 - val_loss: 0.4081\n",
            "Epoch 20/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9291 - loss: 0.1867 - val_accuracy: 0.8859 - val_loss: 0.4503\n",
            "Epoch 21/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9307 - loss: 0.1881 - val_accuracy: 0.8918 - val_loss: 0.4199\n",
            "Epoch 22/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9306 - loss: 0.1833 - val_accuracy: 0.8928 - val_loss: 0.4541\n",
            "Epoch 23/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9307 - loss: 0.1859 - val_accuracy: 0.8893 - val_loss: 0.4771\n",
            "Epoch 24/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9314 - loss: 0.1862 - val_accuracy: 0.8850 - val_loss: 0.5320\n",
            "Epoch 25/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9329 - loss: 0.1776 - val_accuracy: 0.8909 - val_loss: 0.5751\n",
            "Epoch 26/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9359 - loss: 0.1765 - val_accuracy: 0.8969 - val_loss: 0.4857\n",
            "Epoch 27/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9352 - loss: 0.1784 - val_accuracy: 0.8902 - val_loss: 0.5027\n",
            "Epoch 28/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9355 - loss: 0.1714 - val_accuracy: 0.8934 - val_loss: 0.5056\n",
            "Epoch 29/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9374 - loss: 0.1689 - val_accuracy: 0.8910 - val_loss: 0.4960\n",
            "Epoch 30/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9377 - loss: 0.1708 - val_accuracy: 0.8752 - val_loss: 0.7119\n",
            "Epoch 31/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9391 - loss: 0.1733 - val_accuracy: 0.8892 - val_loss: 0.6032\n",
            "Epoch 32/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9370 - loss: 0.1765 - val_accuracy: 0.8813 - val_loss: 0.7350\n",
            "Epoch 33/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9383 - loss: 0.1643 - val_accuracy: 0.8630 - val_loss: 0.7095\n",
            "Epoch 34/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9382 - loss: 0.1656 - val_accuracy: 0.8886 - val_loss: 0.5838\n",
            "Epoch 35/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9386 - loss: 0.1664 - val_accuracy: 0.8932 - val_loss: 0.6282\n",
            "Epoch 36/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9412 - loss: 0.1633 - val_accuracy: 0.8930 - val_loss: 0.6120\n",
            "Epoch 37/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9401 - loss: 0.1648 - val_accuracy: 0.8924 - val_loss: 0.6322\n",
            "Epoch 38/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9398 - loss: 0.1699 - val_accuracy: 0.8919 - val_loss: 0.6201\n",
            "Epoch 39/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9423 - loss: 0.1554 - val_accuracy: 0.8967 - val_loss: 0.6399\n",
            "Epoch 40/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9385 - loss: 0.1632 - val_accuracy: 0.8877 - val_loss: 0.7511\n",
            "Epoch 41/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9416 - loss: 0.1706 - val_accuracy: 0.8881 - val_loss: 0.8427\n",
            "Epoch 42/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9424 - loss: 0.1680 - val_accuracy: 0.8836 - val_loss: 0.6772\n",
            "Epoch 43/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9422 - loss: 0.1594 - val_accuracy: 0.8852 - val_loss: 0.7400\n",
            "Epoch 44/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9418 - loss: 0.1618 - val_accuracy: 0.8947 - val_loss: 0.7181\n",
            "Epoch 45/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9436 - loss: 0.1515 - val_accuracy: 0.8862 - val_loss: 0.7052\n",
            "Epoch 46/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9425 - loss: 0.1596 - val_accuracy: 0.8884 - val_loss: 0.8664\n",
            "Epoch 47/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9434 - loss: 0.1609 - val_accuracy: 0.8923 - val_loss: 0.6581\n",
            "Epoch 48/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9436 - loss: 0.1604 - val_accuracy: 0.8867 - val_loss: 0.8297\n",
            "Epoch 49/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9454 - loss: 0.1657 - val_accuracy: 0.8931 - val_loss: 0.6835\n",
            "Epoch 50/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9465 - loss: 0.1526 - val_accuracy: 0.8838 - val_loss: 0.7813\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8800 - loss: 0.7701\n",
            "Test accuracy: 0.8815\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.85      0.83      1000\n",
            "           1       1.00      0.97      0.99      1000\n",
            "           2       0.83      0.80      0.82      1000\n",
            "           3       0.84      0.93      0.88      1000\n",
            "           4       0.85      0.77      0.81      1000\n",
            "           5       0.99      0.93      0.96      1000\n",
            "           6       0.70      0.73      0.72      1000\n",
            "           7       0.87      0.99      0.92      1000\n",
            "           8       0.98      0.95      0.96      1000\n",
            "           9       0.97      0.90      0.93      1000\n",
            "\n",
            "    accuracy                           0.88     10000\n",
            "   macro avg       0.88      0.88      0.88     10000\n",
            "weighted avg       0.88      0.88      0.88     10000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Будуємо модель\n",
        "model = models.Sequential()\n",
        "\n",
        "# Вхідний шар\n",
        "model.add(layers.Input(shape=(28 * 28,)))\n",
        "\n",
        "# Перший прихований шар\n",
        "model.add(layers.Dense(1024, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
        "model.add(layers.BatchNormalization())  # Додаємо Batch Normalization\n",
        "\n",
        "# Другий прихований шар\n",
        "model.add(layers.Dense(512, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
        "model.add(layers.BatchNormalization())\n",
        "\n",
        "# Третій прихований шар\n",
        "model.add(layers.Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
        "model.add(layers.BatchNormalization())\n",
        "\n",
        "# Четвертий прихований шар\n",
        "model.add(layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
        "model.add(layers.BatchNormalization())\n",
        "\n",
        "# Вихідний шар\n",
        "model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "# Компіляція моделі\n",
        "optimizer = optimizers.SGD(learning_rate=0.001, momentum=0.9)\n",
        "model.compile(optimizer=optimizer,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Callbacks: EarlyStopping та ReduceLROnPlateau\n",
        "early_stopping = callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "reduce_lr = callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=0.00001)\n",
        "\n",
        "# Навчання моделі\n",
        "model.fit(train_images, train_labels_categorical,\n",
        "          epochs=50,\n",
        "          batch_size=64,\n",
        "          validation_split=0.2,\n",
        "          callbacks=[early_stopping, reduce_lr])\n",
        "\n",
        "# Оцінка моделі на тестових даних\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels_categorical)\n",
        "print(f'Test accuracy: {test_acc:.4f}')\n",
        "\n",
        "# Прогнозуємо на тестових даних\n",
        "y_pred = model.predict(test_images)\n",
        "\n",
        "# Перетворимо ймовірності на класи\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_true = test_labels\n",
        "\n",
        "# Виведемо звіт про класифікацію\n",
        "print(classification_report(y_true, y_pred_classes))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qxe-dtNdxTTz",
        "outputId": "8561519c-d500-4418-df90-9e26dfcc1044"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - accuracy: 0.7624 - loss: 2.7670 - val_accuracy: 0.8630 - val_loss: 2.4074 - learning_rate: 0.0010\n",
            "Epoch 2/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8713 - loss: 2.3704 - val_accuracy: 0.8740 - val_loss: 2.3147 - learning_rate: 0.0010\n",
            "Epoch 3/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8905 - loss: 2.2571 - val_accuracy: 0.8757 - val_loss: 2.2506 - learning_rate: 0.0010\n",
            "Epoch 4/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9048 - loss: 2.1643 - val_accuracy: 0.8808 - val_loss: 2.1831 - learning_rate: 0.0010\n",
            "Epoch 5/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9150 - loss: 2.0845 - val_accuracy: 0.8702 - val_loss: 2.1519 - learning_rate: 0.0010\n",
            "Epoch 6/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9226 - loss: 2.0077 - val_accuracy: 0.8812 - val_loss: 2.0818 - learning_rate: 0.0010\n",
            "Epoch 7/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9288 - loss: 1.9384 - val_accuracy: 0.8820 - val_loss: 2.0273 - learning_rate: 0.0010\n",
            "Epoch 8/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9368 - loss: 1.8697 - val_accuracy: 0.8757 - val_loss: 2.0075 - learning_rate: 0.0010\n",
            "Epoch 9/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9423 - loss: 1.8081 - val_accuracy: 0.8788 - val_loss: 1.9462 - learning_rate: 0.0010\n",
            "Epoch 10/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9422 - loss: 1.7554 - val_accuracy: 0.8825 - val_loss: 1.8915 - learning_rate: 0.0010\n",
            "Epoch 11/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9508 - loss: 1.6912 - val_accuracy: 0.8788 - val_loss: 1.8656 - learning_rate: 0.0010\n",
            "Epoch 12/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9517 - loss: 1.6441 - val_accuracy: 0.8866 - val_loss: 1.8075 - learning_rate: 0.0010\n",
            "Epoch 13/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9527 - loss: 1.5961 - val_accuracy: 0.8906 - val_loss: 1.7633 - learning_rate: 0.0010\n",
            "Epoch 14/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9569 - loss: 1.5474 - val_accuracy: 0.8859 - val_loss: 1.7416 - learning_rate: 0.0010\n",
            "Epoch 15/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9587 - loss: 1.5032 - val_accuracy: 0.8842 - val_loss: 1.7125 - learning_rate: 0.0010\n",
            "Epoch 16/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9585 - loss: 1.4596 - val_accuracy: 0.8823 - val_loss: 1.6916 - learning_rate: 0.0010\n",
            "Epoch 17/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9597 - loss: 1.4178 - val_accuracy: 0.8857 - val_loss: 1.6485 - learning_rate: 0.0010\n",
            "Epoch 18/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9620 - loss: 1.3801 - val_accuracy: 0.8877 - val_loss: 1.6032 - learning_rate: 0.0010\n",
            "Epoch 19/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9624 - loss: 1.3407 - val_accuracy: 0.8797 - val_loss: 1.5999 - learning_rate: 0.0010\n",
            "Epoch 20/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9620 - loss: 1.3058 - val_accuracy: 0.8701 - val_loss: 1.6051 - learning_rate: 0.0010\n",
            "Epoch 21/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9628 - loss: 1.2734 - val_accuracy: 0.8722 - val_loss: 1.5651 - learning_rate: 0.0010\n",
            "Epoch 22/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9626 - loss: 1.2398 - val_accuracy: 0.8823 - val_loss: 1.5134 - learning_rate: 0.0010\n",
            "Epoch 23/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9641 - loss: 1.2068 - val_accuracy: 0.8832 - val_loss: 1.4691 - learning_rate: 0.0010\n",
            "Epoch 24/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9657 - loss: 1.1727 - val_accuracy: 0.8833 - val_loss: 1.4515 - learning_rate: 0.0010\n",
            "Epoch 25/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9670 - loss: 1.1373 - val_accuracy: 0.8825 - val_loss: 1.4156 - learning_rate: 0.0010\n",
            "Epoch 26/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9642 - loss: 1.1173 - val_accuracy: 0.8793 - val_loss: 1.4185 - learning_rate: 0.0010\n",
            "Epoch 27/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9654 - loss: 1.0882 - val_accuracy: 0.8776 - val_loss: 1.3941 - learning_rate: 0.0010\n",
            "Epoch 28/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9648 - loss: 1.0618 - val_accuracy: 0.8798 - val_loss: 1.3586 - learning_rate: 0.0010\n",
            "Epoch 29/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9640 - loss: 1.0390 - val_accuracy: 0.8799 - val_loss: 1.3463 - learning_rate: 0.0010\n",
            "Epoch 30/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9655 - loss: 1.0074 - val_accuracy: 0.8788 - val_loss: 1.3040 - learning_rate: 0.0010\n",
            "Epoch 31/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9669 - loss: 0.9831 - val_accuracy: 0.8821 - val_loss: 1.2704 - learning_rate: 0.0010\n",
            "Epoch 32/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9665 - loss: 0.9604 - val_accuracy: 0.8752 - val_loss: 1.2830 - learning_rate: 0.0010\n",
            "Epoch 33/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9667 - loss: 0.9376 - val_accuracy: 0.8761 - val_loss: 1.2597 - learning_rate: 0.0010\n",
            "Epoch 34/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9640 - loss: 0.9214 - val_accuracy: 0.8775 - val_loss: 1.2324 - learning_rate: 0.0010\n",
            "Epoch 35/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9622 - loss: 0.9057 - val_accuracy: 0.8758 - val_loss: 1.2334 - learning_rate: 0.0010\n",
            "Epoch 36/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9656 - loss: 0.8773 - val_accuracy: 0.8821 - val_loss: 1.1632 - learning_rate: 0.0010\n",
            "Epoch 37/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9665 - loss: 0.8513 - val_accuracy: 0.8843 - val_loss: 1.1548 - learning_rate: 0.0010\n",
            "Epoch 38/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9672 - loss: 0.8372 - val_accuracy: 0.8765 - val_loss: 1.1657 - learning_rate: 0.0010\n",
            "Epoch 39/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9620 - loss: 0.8237 - val_accuracy: 0.8816 - val_loss: 1.1357 - learning_rate: 0.0010\n",
            "Epoch 40/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9686 - loss: 0.7935 - val_accuracy: 0.8894 - val_loss: 1.0835 - learning_rate: 0.0010\n",
            "Epoch 41/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9708 - loss: 0.7709 - val_accuracy: 0.8841 - val_loss: 1.0871 - learning_rate: 0.0010\n",
            "Epoch 42/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9649 - loss: 0.7637 - val_accuracy: 0.8779 - val_loss: 1.1037 - learning_rate: 0.0010\n",
            "Epoch 43/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9667 - loss: 0.7446 - val_accuracy: 0.8798 - val_loss: 1.0563 - learning_rate: 0.0010\n",
            "Epoch 44/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9646 - loss: 0.7366 - val_accuracy: 0.8836 - val_loss: 1.0464 - learning_rate: 0.0010\n",
            "Epoch 45/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9665 - loss: 0.7149 - val_accuracy: 0.8708 - val_loss: 1.0861 - learning_rate: 0.0010\n",
            "Epoch 46/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9658 - loss: 0.7004 - val_accuracy: 0.8856 - val_loss: 0.9976 - learning_rate: 0.0010\n",
            "Epoch 47/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9677 - loss: 0.6863 - val_accuracy: 0.8727 - val_loss: 1.0608 - learning_rate: 0.0010\n",
            "Epoch 48/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9675 - loss: 0.6688 - val_accuracy: 0.8866 - val_loss: 0.9883 - learning_rate: 0.0010\n",
            "Epoch 49/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9662 - loss: 0.6548 - val_accuracy: 0.8823 - val_loss: 0.9794 - learning_rate: 0.0010\n",
            "Epoch 50/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9668 - loss: 0.6392 - val_accuracy: 0.8750 - val_loss: 0.9909 - learning_rate: 0.0010\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8761 - loss: 1.0174\n",
            "Test accuracy: 0.8765\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.83      0.83      1000\n",
            "           1       0.98      0.97      0.98      1000\n",
            "           2       0.84      0.71      0.77      1000\n",
            "           3       0.89      0.87      0.88      1000\n",
            "           4       0.77      0.86      0.81      1000\n",
            "           5       0.98      0.94      0.96      1000\n",
            "           6       0.67      0.72      0.70      1000\n",
            "           7       0.88      0.99      0.93      1000\n",
            "           8       0.97      0.95      0.96      1000\n",
            "           9       0.98      0.91      0.94      1000\n",
            "\n",
            "    accuracy                           0.88     10000\n",
            "   macro avg       0.88      0.88      0.88     10000\n",
            "weighted avg       0.88      0.88      0.88     10000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Завантажуємо дані\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "\n",
        "# Нормалізуємо зображення\n",
        "train_images = train_images.astype('float32') / 255\n",
        "test_images = test_images.astype('float32') / 255\n",
        "\n",
        "# Перетворюємо у формат (28, 28, 1)\n",
        "train_images = np.expand_dims(train_images, -1)\n",
        "test_images = np.expand_dims(test_images, -1)\n",
        "\n",
        "# Вибираємо класи, які потрібно збільшити\n",
        "pullover_class = 2\n",
        "shirt_class = 6\n",
        "\n",
        "# Відбираємо лише зображення з класами pullover і shirt\n",
        "pullover_images = train_images[train_labels == pullover_class]\n",
        "pullover_labels = train_labels[train_labels == pullover_class]\n",
        "\n",
        "shirt_images = train_images[train_labels == shirt_class]\n",
        "shirt_labels = train_labels[train_labels == shirt_class]\n",
        "\n",
        "# Зменшимо ступінь аугментації, щоб уникнути переаугментації\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=10,  # Менший поворот\n",
        "    width_shift_range=0.05,  # Менший зсув по ширині\n",
        "    height_shift_range=0.05,  # Менший зсув по висоті\n",
        "    shear_range=0.05,  # Менший зріз\n",
        "    zoom_range=0.05,  # Менше масштабування\n",
        "    horizontal_flip=True  # Тільки дзеркальне відображення\n",
        ")\n",
        "\n",
        "# Генеруємо лише для одного класу (наприклад, тільки для pullover)\n",
        "pullover_augmented = datagen.flow(pullover_images, pullover_labels, batch_size=32, shuffle=False)\n",
        "\n",
        "# Генеруємо тільки трохи додаткових даних\n",
        "augmented_pullover_images = np.concatenate([pullover_augmented.__next__()[0] for _ in range(3)])  # Генеруємо додаткові 3 набори\n",
        "augmented_pullover_labels = np.concatenate([pullover_augmented.__next__()[1] for _ in range(3)])\n",
        "\n",
        "# Об'єднуємо з основним датасетом\n",
        "train_images = np.concatenate([train_images, augmented_pullover_images], axis=0)\n",
        "train_labels = np.concatenate([train_labels, augmented_pullover_labels], axis=0)\n",
        "\n",
        "# Кодуємо мітки\n",
        "train_labels_categorical = to_categorical(train_labels)\n",
        "test_labels_categorical = to_categorical(test_labels)\n",
        "\n",
        "# Будуємо модель\n",
        "model = models.Sequential()\n",
        "\n",
        "model.add(layers.Input(shape=(28, 28, 1)))\n",
        "\n",
        "# Приховані шари\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(1024, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(512, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(256, activation='relu'))\n",
        "\n",
        "# Вихідний шар\n",
        "model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "# Компіляція моделі\n",
        "optimizer = optimizers.Adam()\n",
        "model.compile(optimizer=optimizer,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Навчання моделі\n",
        "model.fit(train_images, train_labels_categorical,\n",
        "          epochs=30,\n",
        "          batch_size=128,\n",
        "          validation_split=0.2)\n",
        "\n",
        "# Оцінка моделі на тестових даних\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels_categorical)\n",
        "print(f'Test accuracy: {test_acc:.4f}')\n",
        "\n",
        "# Прогнозуємо на тестових даних\n",
        "y_pred = model.predict(test_images)\n",
        "\n",
        "# Перетворимо ймовірності на класи\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_true = test_labels\n",
        "\n",
        "# Виведемо звіт про класифікацію\n",
        "print(classification_report(y_true, y_pred_classes))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-m04gEbAtkz",
        "outputId": "f1b97035-55c0-4bbe-e885-e1a7877ede16"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 30ms/step - accuracy: 0.6831 - loss: 1.8686 - val_accuracy: 0.8228 - val_loss: 0.8905\n",
            "Epoch 2/30\n",
            "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8146 - loss: 0.8637 - val_accuracy: 0.8463 - val_loss: 0.6571\n",
            "Epoch 3/30\n",
            "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.8239 - loss: 0.7065 - val_accuracy: 0.8522 - val_loss: 0.5774\n",
            "Epoch 4/30\n",
            "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8298 - loss: 0.6468 - val_accuracy: 0.8426 - val_loss: 0.5866\n",
            "Epoch 5/30\n",
            "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8285 - loss: 0.6204 - val_accuracy: 0.8553 - val_loss: 0.5422\n",
            "Epoch 6/30\n",
            "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8320 - loss: 0.6012 - val_accuracy: 0.8550 - val_loss: 0.5299\n",
            "Epoch 7/30\n",
            "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8305 - loss: 0.5961 - val_accuracy: 0.8552 - val_loss: 0.5332\n",
            "Epoch 8/30\n",
            "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8286 - loss: 0.6060 - val_accuracy: 0.8503 - val_loss: 0.5428\n",
            "Epoch 9/30\n",
            "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8351 - loss: 0.5844 - val_accuracy: 0.8603 - val_loss: 0.5224\n",
            "Epoch 10/30\n",
            "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8306 - loss: 0.5825 - val_accuracy: 0.8594 - val_loss: 0.5101\n",
            "Epoch 11/30\n",
            "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8362 - loss: 0.5801 - val_accuracy: 0.8587 - val_loss: 0.5169\n",
            "Epoch 12/30\n",
            "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8375 - loss: 0.5777 - val_accuracy: 0.8535 - val_loss: 0.5213\n",
            "Epoch 13/30\n",
            "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8354 - loss: 0.5708 - val_accuracy: 0.8592 - val_loss: 0.5020\n",
            "Epoch 14/30\n",
            "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8355 - loss: 0.5720 - val_accuracy: 0.8511 - val_loss: 0.5226\n",
            "Epoch 15/30\n",
            "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8376 - loss: 0.5673 - val_accuracy: 0.8573 - val_loss: 0.5088\n",
            "Epoch 16/30\n",
            "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8418 - loss: 0.5586 - val_accuracy: 0.8631 - val_loss: 0.4970\n",
            "Epoch 17/30\n",
            "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8360 - loss: 0.5653 - val_accuracy: 0.8621 - val_loss: 0.4902\n",
            "Epoch 18/30\n",
            "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8377 - loss: 0.5621 - val_accuracy: 0.8680 - val_loss: 0.4920\n",
            "Epoch 19/30\n",
            "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8378 - loss: 0.5549 - val_accuracy: 0.8616 - val_loss: 0.4893\n",
            "Epoch 20/30\n",
            "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8390 - loss: 0.5490 - val_accuracy: 0.8627 - val_loss: 0.4985\n",
            "Epoch 21/30\n",
            "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8371 - loss: 0.5637 - val_accuracy: 0.8564 - val_loss: 0.4997\n",
            "Epoch 22/30\n",
            "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8330 - loss: 0.5587 - val_accuracy: 0.8640 - val_loss: 0.4942\n",
            "Epoch 23/30\n",
            "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8397 - loss: 0.5604 - val_accuracy: 0.8609 - val_loss: 0.4959\n",
            "Epoch 24/30\n",
            "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8381 - loss: 0.5586 - val_accuracy: 0.8614 - val_loss: 0.4951\n",
            "Epoch 25/30\n",
            "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8395 - loss: 0.5508 - val_accuracy: 0.8577 - val_loss: 0.4953\n",
            "Epoch 26/30\n",
            "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8349 - loss: 0.5620 - val_accuracy: 0.8610 - val_loss: 0.4944\n",
            "Epoch 27/30\n",
            "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8347 - loss: 0.5614 - val_accuracy: 0.8640 - val_loss: 0.4902\n",
            "Epoch 28/30\n",
            "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8398 - loss: 0.5499 - val_accuracy: 0.8651 - val_loss: 0.4843\n",
            "Epoch 29/30\n",
            "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8391 - loss: 0.5506 - val_accuracy: 0.8637 - val_loss: 0.4894\n",
            "Epoch 30/30\n",
            "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8359 - loss: 0.5621 - val_accuracy: 0.8639 - val_loss: 0.4780\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8622 - loss: 0.4913\n",
            "Test accuracy: 0.8578\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.82      0.81      1000\n",
            "           1       0.99      0.96      0.97      1000\n",
            "           2       0.80      0.71      0.75      1000\n",
            "           3       0.83      0.90      0.86      1000\n",
            "           4       0.71      0.83      0.77      1000\n",
            "           5       0.95      0.94      0.95      1000\n",
            "           6       0.69      0.58      0.63      1000\n",
            "           7       0.94      0.91      0.92      1000\n",
            "           8       0.96      0.96      0.96      1000\n",
            "           9       0.92      0.96      0.94      1000\n",
            "\n",
            "    accuracy                           0.86     10000\n",
            "   macro avg       0.86      0.86      0.86     10000\n",
            "weighted avg       0.86      0.86      0.86     10000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Будуємо CNN модель\n",
        "model = models.Sequential()\n",
        "\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(256, activation='relu'))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "# Компіляція моделі\n",
        "optimizer = optimizers.Adam()\n",
        "model.compile(optimizer=optimizer,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Навчання моделі\n",
        "model.fit(train_images, train_labels_categorical,\n",
        "          epochs=30,\n",
        "          batch_size=128,\n",
        "          validation_split=0.2)\n",
        "\n",
        "# Оцінка моделі на тестових даних\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels_categorical)\n",
        "print(f'Test accuracy: {test_acc:.4f}')\n",
        "\n",
        "# Прогнозуємо на тестових даних\n",
        "y_pred = model.predict(test_images)\n",
        "\n",
        "# Перетворимо ймовірності на класи\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_true = test_labels\n",
        "\n",
        "# Виведемо звіт про класифікацію\n",
        "print(classification_report(y_true, y_pred_classes))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4OXZnbPLDzN3",
        "outputId": "c94e3bb7-46af-4b01-f5f6-c1a74db4eeda"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 21ms/step - accuracy: 0.5273 - loss: 1.2675 - val_accuracy: 0.7964 - val_loss: 0.5456\n",
            "Epoch 2/30\n",
            "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7971 - loss: 0.5671 - val_accuracy: 0.8281 - val_loss: 0.4637\n",
            "Epoch 3/30\n",
            "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8336 - loss: 0.4623 - val_accuracy: 0.8575 - val_loss: 0.3899\n",
            "Epoch 4/30\n",
            "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8538 - loss: 0.4096 - val_accuracy: 0.8667 - val_loss: 0.3573\n",
            "Epoch 5/30\n",
            "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8707 - loss: 0.3632 - val_accuracy: 0.8719 - val_loss: 0.3453\n",
            "Epoch 6/30\n",
            "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8779 - loss: 0.3430 - val_accuracy: 0.8709 - val_loss: 0.3441\n",
            "Epoch 7/30\n",
            "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8931 - loss: 0.3048 - val_accuracy: 0.8801 - val_loss: 0.3216\n",
            "Epoch 8/30\n",
            "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8913 - loss: 0.2966 - val_accuracy: 0.8752 - val_loss: 0.3419\n",
            "Epoch 9/30\n",
            "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9029 - loss: 0.2685 - val_accuracy: 0.8905 - val_loss: 0.3081\n",
            "Epoch 10/30\n",
            "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9096 - loss: 0.2528 - val_accuracy: 0.8862 - val_loss: 0.3119\n",
            "Epoch 11/30\n",
            "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9147 - loss: 0.2387 - val_accuracy: 0.8830 - val_loss: 0.3168\n",
            "Epoch 12/30\n",
            "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9184 - loss: 0.2287 - val_accuracy: 0.8878 - val_loss: 0.3119\n",
            "Epoch 13/30\n",
            "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9208 - loss: 0.2190 - val_accuracy: 0.8928 - val_loss: 0.3061\n",
            "Epoch 14/30\n",
            "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9289 - loss: 0.2004 - val_accuracy: 0.8944 - val_loss: 0.3111\n",
            "Epoch 15/30\n",
            "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9264 - loss: 0.2062 - val_accuracy: 0.8876 - val_loss: 0.3226\n",
            "Epoch 16/30\n",
            "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9302 - loss: 0.1914 - val_accuracy: 0.8969 - val_loss: 0.3228\n",
            "Epoch 17/30\n",
            "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9363 - loss: 0.1749 - val_accuracy: 0.8941 - val_loss: 0.3374\n",
            "Epoch 18/30\n",
            "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9398 - loss: 0.1678 - val_accuracy: 0.8968 - val_loss: 0.3249\n",
            "Epoch 19/30\n",
            "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9408 - loss: 0.1608 - val_accuracy: 0.8933 - val_loss: 0.3360\n",
            "Epoch 20/30\n",
            "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9444 - loss: 0.1521 - val_accuracy: 0.8959 - val_loss: 0.3411\n",
            "Epoch 21/30\n",
            "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9466 - loss: 0.1422 - val_accuracy: 0.8931 - val_loss: 0.3695\n",
            "Epoch 22/30\n",
            "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9514 - loss: 0.1383 - val_accuracy: 0.8911 - val_loss: 0.3915\n",
            "Epoch 23/30\n",
            "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9513 - loss: 0.1302 - val_accuracy: 0.8939 - val_loss: 0.3795\n",
            "Epoch 24/30\n",
            "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9515 - loss: 0.1316 - val_accuracy: 0.8987 - val_loss: 0.3676\n",
            "Epoch 25/30\n",
            "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9548 - loss: 0.1257 - val_accuracy: 0.8968 - val_loss: 0.3901\n",
            "Epoch 26/30\n",
            "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9556 - loss: 0.1181 - val_accuracy: 0.8942 - val_loss: 0.4139\n",
            "Epoch 27/30\n",
            "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9582 - loss: 0.1118 - val_accuracy: 0.8972 - val_loss: 0.4221\n",
            "Epoch 28/30\n",
            "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9597 - loss: 0.1070 - val_accuracy: 0.8962 - val_loss: 0.4144\n",
            "Epoch 29/30\n",
            "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9635 - loss: 0.0976 - val_accuracy: 0.8979 - val_loss: 0.4308\n",
            "Epoch 30/30\n",
            "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9651 - loss: 0.0940 - val_accuracy: 0.8941 - val_loss: 0.4549\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8884 - loss: 0.5061\n",
            "Test accuracy: 0.8905\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.83      0.84      1000\n",
            "           1       0.99      0.97      0.98      1000\n",
            "           2       0.84      0.83      0.83      1000\n",
            "           3       0.88      0.91      0.89      1000\n",
            "           4       0.82      0.84      0.83      1000\n",
            "           5       0.95      0.98      0.97      1000\n",
            "           6       0.71      0.68      0.69      1000\n",
            "           7       0.97      0.92      0.94      1000\n",
            "           8       0.97      0.97      0.97      1000\n",
            "           9       0.94      0.97      0.96      1000\n",
            "\n",
            "    accuracy                           0.89     10000\n",
            "   macro avg       0.89      0.89      0.89     10000\n",
            "weighted avg       0.89      0.89      0.89     10000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.applications import MobileNetV2\n",
        "from keras.applications.mobilenet_v2 import preprocess_input\n",
        "\n",
        "# Завантажуємо та нормалізуємо дані\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "train_images = np.stack([train_images]*3, axis=-1)  # Робимо 3 канали замість 1\n",
        "test_images = np.stack([test_images]*3, axis=-1)\n",
        "\n",
        "# Нормалізація для MobileNet\n",
        "train_images = preprocess_input(train_images.astype('float32'))\n",
        "test_images = preprocess_input(test_images.astype('float32'))\n",
        "\n",
        "# Збільшуємо розмір зображень до 96x96 (розмір вхідних зображень для MobileNet)\n",
        "train_images = tf.image.resize(train_images, (96, 96))\n",
        "test_images = tf.image.resize(test_images, (96, 96))\n",
        "\n",
        "# Кодуємо мітки\n",
        "train_labels_categorical = to_categorical(train_labels)\n",
        "test_labels_categorical = to_categorical(test_labels)\n",
        "\n",
        "# Завантажуємо попередньо навчений MobileNetV2 без верхніх шарів\n",
        "base_model = MobileNetV2(input_shape=(96, 96, 3), include_top=False, weights='imagenet')\n",
        "\n",
        "# Заморожуємо базову модель\n",
        "base_model.trainable = False\n",
        "\n",
        "# Будуємо модель зверху MobileNet\n",
        "model = models.Sequential([\n",
        "    base_model,\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dense(256, activation='relu'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Компіляція моделі\n",
        "optimizer = optimizers.Adam()\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Навчання моделі\n",
        "model.fit(train_images, train_labels_categorical, epochs=30, batch_size=128, validation_split=0.2)\n",
        "\n",
        "# Оцінка моделі\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels_categorical)\n",
        "print(f'Test accuracy: {test_acc:.4f}')\n",
        "\n",
        "# Прогнозування на тестових даних\n",
        "y_pred = model.predict(test_images)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# Виведемо звіт про класифікацію\n",
        "print(classification_report(test_labels, y_pred_classes))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vf3hjd6REuZk",
        "outputId": "a497e837-3ca0-40a9-9c1b-f6328f38adf3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_96_no_top.h5\n",
            "\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n",
            "Epoch 1/30\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 55ms/step - accuracy: 0.7796 - loss: 0.6433 - val_accuracy: 0.8806 - val_loss: 0.3119\n",
            "Epoch 2/30\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 36ms/step - accuracy: 0.8784 - loss: 0.3322 - val_accuracy: 0.8939 - val_loss: 0.2829\n",
            "Epoch 3/30\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 34ms/step - accuracy: 0.8916 - loss: 0.2934 - val_accuracy: 0.8968 - val_loss: 0.2722\n",
            "Epoch 4/30\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 35ms/step - accuracy: 0.8991 - loss: 0.2749 - val_accuracy: 0.8997 - val_loss: 0.2688\n",
            "Epoch 5/30\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 36ms/step - accuracy: 0.9051 - loss: 0.2562 - val_accuracy: 0.8992 - val_loss: 0.2699\n",
            "Epoch 6/30\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 37ms/step - accuracy: 0.9078 - loss: 0.2409 - val_accuracy: 0.9070 - val_loss: 0.2512\n",
            "Epoch 7/30\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 35ms/step - accuracy: 0.9150 - loss: 0.2313 - val_accuracy: 0.9065 - val_loss: 0.2564\n",
            "Epoch 8/30\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 34ms/step - accuracy: 0.9175 - loss: 0.2225 - val_accuracy: 0.9054 - val_loss: 0.2612\n",
            "Epoch 9/30\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 35ms/step - accuracy: 0.9212 - loss: 0.2094 - val_accuracy: 0.9079 - val_loss: 0.2522\n",
            "Epoch 10/30\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 34ms/step - accuracy: 0.9269 - loss: 0.1968 - val_accuracy: 0.9077 - val_loss: 0.2544\n",
            "Epoch 11/30\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 35ms/step - accuracy: 0.9264 - loss: 0.1961 - val_accuracy: 0.9096 - val_loss: 0.2558\n",
            "Epoch 12/30\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 41ms/step - accuracy: 0.9324 - loss: 0.1830 - val_accuracy: 0.9096 - val_loss: 0.2575\n",
            "Epoch 13/30\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 42ms/step - accuracy: 0.9334 - loss: 0.1775 - val_accuracy: 0.9068 - val_loss: 0.2580\n",
            "Epoch 14/30\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 35ms/step - accuracy: 0.9359 - loss: 0.1709 - val_accuracy: 0.9074 - val_loss: 0.2656\n",
            "Epoch 15/30\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 35ms/step - accuracy: 0.9342 - loss: 0.1697 - val_accuracy: 0.9057 - val_loss: 0.2720\n",
            "Epoch 16/30\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 35ms/step - accuracy: 0.9393 - loss: 0.1603 - val_accuracy: 0.9064 - val_loss: 0.2727\n",
            "Epoch 17/30\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 34ms/step - accuracy: 0.9397 - loss: 0.1572 - val_accuracy: 0.9116 - val_loss: 0.2688\n",
            "Epoch 18/30\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 35ms/step - accuracy: 0.9433 - loss: 0.1498 - val_accuracy: 0.9108 - val_loss: 0.2655\n",
            "Epoch 19/30\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 35ms/step - accuracy: 0.9443 - loss: 0.1494 - val_accuracy: 0.9100 - val_loss: 0.2805\n",
            "Epoch 20/30\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 34ms/step - accuracy: 0.9487 - loss: 0.1350 - val_accuracy: 0.9118 - val_loss: 0.2718\n",
            "Epoch 21/30\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 35ms/step - accuracy: 0.9470 - loss: 0.1345 - val_accuracy: 0.9103 - val_loss: 0.2795\n",
            "Epoch 22/30\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 35ms/step - accuracy: 0.9518 - loss: 0.1279 - val_accuracy: 0.9112 - val_loss: 0.2838\n",
            "Epoch 23/30\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 34ms/step - accuracy: 0.9519 - loss: 0.1269 - val_accuracy: 0.9076 - val_loss: 0.2953\n",
            "Epoch 24/30\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 34ms/step - accuracy: 0.9495 - loss: 0.1278 - val_accuracy: 0.9069 - val_loss: 0.3013\n",
            "Epoch 25/30\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 36ms/step - accuracy: 0.9545 - loss: 0.1188 - val_accuracy: 0.9097 - val_loss: 0.3050\n",
            "Epoch 26/30\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 35ms/step - accuracy: 0.9534 - loss: 0.1192 - val_accuracy: 0.9091 - val_loss: 0.3038\n",
            "Epoch 27/30\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 35ms/step - accuracy: 0.9579 - loss: 0.1092 - val_accuracy: 0.9120 - val_loss: 0.3105\n",
            "Epoch 28/30\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 35ms/step - accuracy: 0.9575 - loss: 0.1095 - val_accuracy: 0.9099 - val_loss: 0.3123\n",
            "Epoch 29/30\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 35ms/step - accuracy: 0.9593 - loss: 0.1044 - val_accuracy: 0.9093 - val_loss: 0.3178\n",
            "Epoch 30/30\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 35ms/step - accuracy: 0.9612 - loss: 0.1011 - val_accuracy: 0.9101 - val_loss: 0.3070\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - accuracy: 0.9023 - loss: 0.3254\n",
            "Test accuracy: 0.9051\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.90      0.86      1000\n",
            "           1       0.99      0.97      0.98      1000\n",
            "           2       0.88      0.84      0.86      1000\n",
            "           3       0.88      0.89      0.89      1000\n",
            "           4       0.82      0.89      0.85      1000\n",
            "           5       0.98      0.98      0.98      1000\n",
            "           6       0.76      0.67      0.72      1000\n",
            "           7       0.95      0.96      0.96      1000\n",
            "           8       0.98      0.99      0.98      1000\n",
            "           9       0.97      0.96      0.96      1000\n",
            "\n",
            "    accuracy                           0.91     10000\n",
            "   macro avg       0.90      0.91      0.90     10000\n",
            "weighted avg       0.90      0.91      0.90     10000\n",
            "\n"
          ]
        }
      ]
    }
  ]
}